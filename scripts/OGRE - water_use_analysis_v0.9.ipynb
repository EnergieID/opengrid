{
 "metadata": {
  "name": "",
  "signature": "sha256:008a6ade103d7898e061cba8fb06896e3a43e9577268d3f902894dab50491c40"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## This script shows how to make some usage profile comparisons (mainly against own historic utility usage)\n",
      "###For this purpose, following visualisations are used:\n",
      "####A) a load_duration_curve is shown (over the selected period),  \\n\n",
      "####B) Pie charts (grouped per bin), to evaluate the relative impact of each class \\n\n",
      "####C) Utility usage frequency, duration, and intensity are calculated per bin,and shown in histogram or scatter plots \n",
      "(length vs frequency, per bin)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# some imports & opengridCC setup\n",
      "\n",
      "import os, sys\n",
      "import inspect\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from matplotlib.dates import HourLocator, DateFormatter\n",
      "import datetime as dt\n",
      "import pytz\n",
      "BXL = pytz.timezone('Europe/Brussels')\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "\n",
      "script_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
      "# add the path to opengrid to sys.path\n",
      "sys.path.append(os.path.join(script_dir, os.pardir, os.pardir))\n",
      "from opengrid.library import config\n",
      "from opengrid.library import houseprint\n",
      "from opengrid.library import fluksoapi\n",
      "# load units library\n",
      "from carpetplot.library import genmodule as units\n",
      "#import carpetplot.library.genmodule as units\n",
      "\n",
      "import pytz\n",
      "c = config.Config()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Script settings"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize']=14/2,8/2\n",
      "path_to_data = c.get('data', 'folder')\n",
      "#path_to_data = 'SET_CUSTOM_PATH_HERE'\n",
      "\n",
      "if not os.path.exists(path_to_data):\n",
      "    raise IOError(\"Provide your path to the data.  This is a folder containing a 'zip' and 'csv' subfolder.\")\n",
      "else:\n",
      "    path_to_csv = os.path.join(path_to_data, 'csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chosen_type = 0\n",
      "#  0 =water, 1 = gas, 2 = electricity : choose your type of analysis.\n",
      "\n",
      "\n",
      "#default values:\n",
      "UtilityTypes = ['water', 'gas','electricity'] # {'water','gas','electricity'} \n",
      "utility =  UtilityTypes[chosen_type] # here 'water'\n",
      "util =utility\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### We create a list with dataframes convert it to more usefull units.\n",
      "Each dataframe contains all utility consumption data we have available.\n",
      "Then it is filtered to a specific time period and filtered to one example series (one fluksometer)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hp = houseprint.load_houseprint_from_file('hp_anonymous.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#load data and convert to usefull plotting unit\n",
      "fl_unit = units.get_units(util,usage='fl',ref='base') #l/day for W\n",
      "bUnit = units.get_units(util,usage='pl',ref='base') # l/min for W\n",
      "tIntUnits = units.get_units(util,usage='pl',ref='int')\n",
      "\n",
      "CF = units.get_conversionfactor(util, fromusage='fl', fromref='base', tousage='pl', toref='base', what='cf', str_incl_units=False, qty=1)\n",
      "# CF  = 1440.0 (l/day to l/min for water)\n",
      "CF_str = units.get_conversionfactor(util, fromusage='fl', fromref='base', tousage='pl', toref='base', what='cf', str_incl_units=True, qty=24)\n",
      "print CF_str\n",
      "print CF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "print 'Loading', utility ,'-data and converting from ',fl_unit ,' to ',bUnit,':'\n",
      "\n",
      "\n",
      "#put all available utlity sensors in a dataframe\n",
      "dataframes = []\n",
      "sensors = hp.get_sensors_by_type(utility)\n",
      "for sensor in sensors:\n",
      "    FL =hp.get_flukso_from_sensor(sensor)\n",
      "    csv = fluksoapi.find_csv(path_to_csv, sensor)\n",
      "    if len(csv) <> 0:\n",
      "        data=fluksoapi.load_csv(csv)\n",
      "        if len(data)>0:\n",
      "            dataframes.append(data)\n",
      "            #print FL, ' loaded correctly with sensor', data.columns[0]\n",
      "    #else:\n",
      "            #print FL, sensor, 'not loaded\n",
      "print('{} {}-sensors loaded.'.format(len(dataframes),utility))\n",
      "\n",
      "#dataframes = list of dataframes\n",
      "df = dataframes[0].join(dataframes[1:], how='outer')\n",
      "\n",
      "# remove null columns\n",
      "df.dropna(axis=1, how='all', inplace=True)\n",
      "print('{} Sensors with data retained'.format(len(df.columns))) \n",
      "\n",
      "# convert the dataframe to LOCAL TIME (BRUSSELS)\n",
      "df.index = df.index.tz_convert(pytz.timezone('Europe/Brussels'))\n",
      "#df is a joined pandas dataframe\n",
      "\n",
      "# apply conversion factor, dependent on type of utility (to be checked!!) \n",
      "df = df*CF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " # extract data of 1 sensor, specific time period, to have faster calculations (here: 14 days)\n",
      "sensors = hp.get_sensors_by_type(utility)\n",
      "sensor=sensors[1]\n",
      "from_date = pd.datetime.today()-dt.timedelta(days=15)\n",
      "to_date = pd.datetime.today()-dt.timedelta(days=1)\n",
      "FL = hp.get_flukso_from_sensor(sensor) \n",
      "\n",
      "#make small subset and slice of one sensor to use in rest of script:\n",
      "smaller_df =df.ix[from_date:to_date] # (contains XX day slice of all water sensors)\n",
      "example_series =smaller_df[sensor] #one random sensor timeseries slice of XX days = 14 days atm\n",
      "example_series.dropna(inplace=True) #fails withouth inplace true!\n",
      "example_series.name = FL\n",
      "\n",
      "# make some usefull limits lists\n",
      "limH = max(example_series)\n",
      "limL = min(example_series)\n",
      "lims = np.arange(1,20,0.5)\n",
      "print 'Utility data values vary between', limL,'and',limH , bUnit\n",
      "example_series.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Below, several new subfunctions are shown (cross,occurence_in_bin, interval_data, and  Pie_WUsage). A short Example code for each subfunction is always right below the function (commented out with #)\n",
      "#### Below the code definitions, longer (more usefull) examples are given. \n",
      "\n",
      "#### Each script uses a single timeseries (for example example_series), which can be any \"water, gas or elec\" usage timeseries, typically of length 14 days and at minute resolution (but can be much longer) \n",
      "#### The analysis is designed for /makes most sense for <bold>water data.</bold>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_duplicates(ts):\n",
      "    ''' \n",
      "    Hack to remove duplicate date entries. Keeps the 'first' one\n",
      "    Source: http://www.asktheguru.info/kb/viewanswer/29968238/\n",
      "    '''\n",
      "    return pd.TimeSeries(ts.to_dict())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nona = example_series.dropna()\n",
      "nodup =nona.drop_duplicates()\n",
      "nodup.plot()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def tscombine(ts1,ts2):\n",
      "    ''' \n",
      "    Combine two timeseries (combine first) keeps data and info from the 'first' one.\n",
      "    '''\n",
      "    ts1=remove_duplicates(ts1)\n",
      "    ts2=remove_duplicates(ts2)\n",
      "    if (ts1.count()<>0) & (ts2.count()<>0):\n",
      "        try:        \n",
      "            #still gives error sometimes... Why?\n",
      "            #ValueError: cannot reindex from a duplicate axis.\n",
      "            combined = ts1.combine_first(ts2)\n",
      "        except:\n",
      "            #ts1 =remove_duplicates(ts1)\n",
      "            #ts2 =remove_duplicates(ts2) #doesnt help (different type?): 2values given\n",
      "            onedf =pd.DataFrame(data = [ts2.values], index = [ts2.index], name= ts2.name)\n",
      "            pd.DataFrame.T.append(ts1,ignore_index = True)\n",
      "    elif ts1.count()==0:\n",
      "        if ts2.count()==0:\n",
      "            #both empty... return nothing? or valueerror    \n",
      "            raise ValueError('Both timeseries empty!')\n",
      "        else:\n",
      "            combined = ts2\n",
      "    elif ts2.count()==0:\n",
      "        combined = ts1\n",
      "    else:\n",
      "        combined = ts1\n",
      "        raise ValueError('2 empty data series cannot be joined')\n",
      "    #ts_cr = remove_duplicates(combined)\n",
      "    return combined\n",
      "    \n",
      "    '''\n",
      "    #possible alternative 1\n",
      "    df = pd.DataFrame.join([ts1,ts2],how='outer')\n",
      "    combined = pd.TimeSeries(df[0])\n",
      "    return combined\n",
      "    ## fails more than current method.\n",
      "    \n",
      "     #alternative method 2\n",
      "     #return pd.concat([ts1,ts2])\n",
      "    \n",
      "    '''\n",
      "    \n",
      "    #example\n",
      "ts_try =tscombine(example_series,tsLc)\n",
      "\n",
      "tscomb =tscombine(LC,HC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross(series, cross=0, direction='cross'):\n",
      "    \"\"\"\n",
      "    Given a Series, this function returns all the index values and a DF of where the data values equal \n",
      "    the 'cross' value. \n",
      "\n",
      "    Direction can be 'rising' (for rising edge), 'falling' (for only falling \n",
      "    edge), or 'cross' for both edges\n",
      "    author: Daylyglen:\n",
      "    url: http://stackoverflow.com/questions/10475488/calculating-crossing-intercept-points-of-a-series-or-dataframe\n",
      "\n",
      "    Ryton: added valueerror / dual output at edge, timezone thingies, and some more.\n",
      "    \"\"\"\n",
      "    #sanity check:\n",
      "    nocross = False\n",
      "    if cross > max(series):          \n",
      "        nocross = True\n",
      "        boundary = max(series)\n",
      "    elif cross < min(series):\n",
      "        nocross = True\n",
      "        boundary = min(series)\n",
      "        \n",
      "    \n",
      "    if nocross == True:\n",
      "        first_index = series.first_valid_index()\n",
      "        last_index = series.last_valid_index()\n",
      "        nocross_dt = pd.DatetimeIndex([first_index,last_index],name = 'Date')\n",
      "        return nocross_dt, pd.TimeSeries(data= [ boundary,boundary], index = nocross_dt,name='No_crossings')  \n",
      "        #raise ValueError('Requested value out of series boundaries. No crossing returned')\n",
      "        \n",
      "    # Find if values are above or bellow yvalue crossing:\n",
      "    above=series.values > cross\n",
      "    below=np.logical_not(above)\n",
      "    left_shifted_above = above[1:]\n",
      "    left_shifted_below = below[1:]\n",
      "    x_crossings = []\n",
      "    # Find indexes on left side of crossing point\n",
      "    if direction == 'rising':\n",
      "        idxs = (left_shifted_above & below[0:-1]).nonzero()[0]\n",
      "    elif direction == 'falling':\n",
      "        idxs = (left_shifted_below & above[0:-1]).nonzero()[0]\n",
      "    else:\n",
      "        rising = left_shifted_above & below[0:-1]\n",
      "        falling = left_shifted_below & above[0:-1]\n",
      "        idxs = (rising | falling).nonzero()[0]\n",
      "\n",
      "    # Calculate x crossings with interpolation using formula for a line:\n",
      "    x1 = series.index.values[idxs]\n",
      "    x2 = series.index.values[idxs+1]\n",
      "    y1 = series.values[idxs]\n",
      "    y2 = series.values[idxs+1]\n",
      "    x_crossings = (cross-y1)*(x2-x1)/(y2-y1) + x1\n",
      "\n",
      "    not_rounded = pd.DatetimeIndex(x_crossings)\n",
      "    #rounded_to_ns = pd.DatetimeIndex(np.round(not_rounded.astype(np.int64), -9).astype('datetime64[ns]'))\n",
      "    rounded_to_sec = pd.DatetimeIndex(((not_rounded.asi8/(1e9)).round()*1e9).astype(np.int64),name = 'Date')\n",
      "    #rounded_to_min = pd.DatetimeIndex(((not_rounded.asi8/(1e9*60)).round()*1e9*60).astype(np.int64))\n",
      "    #roudn to min creates duplicates, and often misses important info! Not an option at this stage.\n",
      "    crossing_index = rounded_to_sec.tz_localize(BXL) \n",
      "    #ncrossings = len(crossing_index) \n",
      "    cross_ts = pd.TimeSeries(data = cross, index =crossing_index, name = 'crossings')\n",
      "    for i in arange(len(crossing_index),0):\n",
      "        if 'NaT' == crossing_index[i]: #cut out the NotaTime (no idea why it occurs)\n",
      "            crossing_index.ix[i].remove\n",
      "            cross[crossing_index.ix[i]].remove\n",
      "        elif 'NaN' == cross_ts[i]: #cut out the NotaNumber\n",
      "            crossing_index.ix[i].remove\n",
      "            cross[crossing_index.ix[i]].remove\n",
      "    crossDateTime = pd.TimeSeries(data = cross, index =crossing_index, name = 'crossings')\n",
      "    cross_index = crossDateTime.index\n",
      "    \n",
      "    return cross_index,crossDateTime\n",
      "\n",
      "\n",
      "#small example\n",
      "LL =4.#l/min, LimLow\n",
      "LH = 2. #l/min, LimLow\n",
      "posLc,tsLc = cross(example_series, LL)\n",
      "posHc,tsHc = cross(example_series, LH )            \n",
      "\n",
      "print  'Output List available in datetime format:', posLc[:]\n",
      "print 'Or in timeseries with all crossing values:'\n",
      "tsLc.head()\n",
      "#some stats\n",
      "print tsLc.count(), tsLc.name,' at', LL , bUnit\n",
      "print tsHc.count(), tsHc.name,' at', LH, bUnit\n",
      "ts =tscombine(tsLc,tsHc)\n",
      "print ts.count(), ts.name, 'total'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def occurence_in_bin(series, LimLow = 8 , LimHigh = 1000):\n",
      "    \"\"\"\n",
      "    Purpose:\n",
      "    Calculates number of times the timeseries is in the bin between limlow & limHigh. \n",
      "    Can help to assess # of events.\n",
      "    \n",
      "    Inputs:\n",
      "    * series: pandas timeseries (1x n vector)\n",
      "    * Lim low = lower limit of checking, in l/min # * *60*24?\n",
      "    * Upper limit in l/min. can be +inf\n",
      "    \n",
      "        output: number of crossings above lim low, but below lim-hihg (thus summed NUMBER of water usages (minutes) in a specific bin.\n",
      "    \"\"\"\n",
      "    crossposLr,notused = cross(series, LimLow, 'rising')\n",
      "    crossposHf,notused = cross(series, LimHigh, 'falling')\n",
      "    \"print crossposL \"\n",
      "    try:\n",
      "        n_occ =crossposLr.size + crossposHf().size\n",
      "    except:\n",
      "        n_occ = crossposLr.size\n",
      "    return n_occ\n",
      "\n",
      "#small examples\n",
      "#random_sample = pd.TimeSeries([0,2,3,6,2,4.2,4.5,3,2,1,4,3,0])\n",
      "\n",
      "LL = 10\n",
      "LH = 20\n",
      "n_occ = occurence_in_bin(example_series, LimLow = LL, LimHigh = LH) \n",
      "print 'number of interval occurence: ', n_occ,' times a utility usage (water draw) occured between ', str(LL), bUnit,' and ',LH, bUnit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def time_in_interval(series, LimLow = 0.1,LimHigh = 1000, TH_time = 0, summed = False):\n",
      "\n",
      "    \"\"\"\n",
      "    Purpose: Gives list of TIME DURATION in preferred timescale (e.g. minutes) where the series was between limLow and LimHigh. \n",
      "    Alternatively (with prop='volume' flag), integrated VOLUMES per interval are be available \n",
      "\n",
      "    Inputs:\n",
      "    * series: pd TimeSeries (1x n vector) (already in 'default plotting' values) (eg. l/min) \n",
      "    * Lim low = lower limit of checking, in same units\n",
      "    * LimHigh Upper limit of checking, in same units\n",
      "    * TH_time = if time in interval (in timescale) below this value => interval IGNORED for volume or time checks\n",
      "\n",
      "    * prop flag=  if 'times', \n",
      "             resident_length of water usage in the range. #timedelta.\n",
      "    average_time: timedelta\n",
      "    if  prop == 'volumeso\n",
      "            resident volumes of water usage during the #timedelta range\n",
      "    timescale = 's', 'h', 'min', to give output in this unit (else nanoseconds...).\n",
      "    \"\"\"\n",
      "    resident_length = 0\n",
      "    #both in and out\n",
      "    posLc,tsLc = cross(series, LimLow, 'cross')\n",
      "    posHc,tsHc = cross(series, LimHigh, 'cross')\n",
      "            #into\n",
      "    posLr,tsLr = cross(series, LimLow, 'rising')\n",
      "    posHf,tsHf = cross(series, LimHigh, 'falling')\n",
      "    #out\n",
      "    posHr,tsHr = cross(series, LimHigh, 'rising')\n",
      "    posLf,tsLf = cross(series, LimLow, 'falling')\n",
      "    if (len(posHc) >0) &(len(posLc) >0): # both high and low crossings\n",
      "        ts_cross = tscombine(tsHc,tsLc)\n",
      "        crossings = ts_cross.index\n",
      "    elif len(posHc)==0: # NO crossing of highest limit\n",
      "        if len(posLc)==0: # NO crossing of lowest limit\n",
      "            return [0] #no data in interval\n",
      "        else:\n",
      "            ts_cross = tsLc            \n",
      "    else: \n",
      "        ts_cross = tsHc            \n",
      "\n",
      "\n",
      "    #print(crossposLf,n_time_occ)\n",
      "\n",
      "    \n",
      "    interval_lengths = np.zeros([len(crossings)-1])\n",
      "    prop = 'times'\n",
      "    if prop == 'times':\n",
      "        if len(crossings) ==0:\n",
      "            return 0\n",
      "        elif len(crossings)>0:\n",
      "            for i in arange(0, len(crossings)-1):\n",
      "                tdelta = crossings[i+1]-crossings[i] # in seconds and days.\n",
      "                interval_lengths[i]=( tdelta.seconds +tdelta.days*24*60*60) # SECONDS\n",
      "\n",
      "            if (posLr[0] == posHr[0])|(posLf[0] == posHf[0]):\n",
      "                #both outside/on boundary =>\n",
      "                resident_length = [0]       \n",
      "            \n",
      "            elif ((crossings[0] == posLr[0])| (crossings[0] == posHf[0])):\n",
      "                #print 'case A'\n",
      "                #series started below LowLim interval, thus keep all diff.\n",
      "                resident_length = interval_lengths[0:-1:2]\n",
      "            \n",
      "            elif ((crossings[0] == posLf[0]) |(crossings[0] == posHr[0])): \n",
      "                #print 'case B'\n",
      "                #series started inside interval, thus drop first of into (and maybe last)\n",
      "                resident_length = interval_lengths[1:-2:2]\n",
      "        else:  #if no crossing \n",
      "            return [0]\n",
      "            \n",
      "    if (TH_time > 0):\n",
      "            #remove tiny intervals of residentlength (make them zero, then remove).\n",
      "            resident_length= resident_length[resident_length>TH_time]\n",
      "            '''if max(resident_length)>TH_time:\n",
      "                resident_length[np.greater_equal(TH_time,resident_length)] = 0  #if TH_time >= reslength => ==0\n",
      "                resident_length =resident_length[resident_length>0]\n",
      "            else:\n",
      "                resident_length = 0\n",
      "            '''\n",
      "    total_time = round(np.nansum(resident_length,axis=0),1) #sum in seconds\n",
      "            \n",
      "    if summed==False:\n",
      "        # return non-zero elements\n",
      "        return resident_length\n",
      "        # return non-zero elements\n",
      "    else:\n",
      "        return total_time\n",
      "    \n",
      "# Short Example \n",
      "# Give time interval lengths (time in minutes) each time the data was in tapping interval:\n",
      "LL = 10\n",
      "LH = 20\n",
      "resident_length  = time_in_interval(example_series, LimLow = LL,LimHigh = LH, \n",
      "                                     TH_time =  60)\n",
      "\n",
      "print 'Length of each usage interval occurence in seconds:'\n",
      "print resident_length #pd.DataFrame\n",
      "\n",
      "total_time = round(np.nansum(resident_length,axis=0)/3600.,1) # in hours\n",
      "total_time2 = time_in_interval(example_series, LimLow = LL,LimHigh = LH, \n",
      "                                     TH_time =  60,summed =True)/3600.# s /(3600s/hr) => in hours\n",
      "\n",
      "print 'Total (summed) time in all intervals during whole time horizon:', total_time , ' = ', total_time2, 'h'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def volume_in_interval(series, LimLow = 0.1,LimHigh = 1000, TH_time = 0, summed = False, plottoo = True,CF_ts_to_s = 1/60. ):\n",
      "\n",
      "    \"\"\"\n",
      "    Purpose: Gives list of TIME DURATION in preferred timescale (e.g. minutes) where the series was between limLow and LimHigh. \n",
      "    Alternatively (with prop='volume' flag), integrated VOLUMES per interval are be available \n",
      "\n",
      "    Inputs:\n",
      "    * series: pd TimeSeries (1x n vector) (already in 'default plotting' values) (eg. l/min) \n",
      "    * Lim low = lower limit of checking, in same units\n",
      "    * LimHigh Upper limit of checking, in same units\n",
      "    * TH_time = if time in interval (in timescale) below this value => interval IGNORED for volume or time checks\n",
      "\n",
      "    * prop flag=  if 'times', \n",
      "             resident_length of water usafge in the range. #timedelta.\n",
      "    if  prop == 'volumes'\n",
      "            resident volumes of water usage during the #timedelta range\n",
      "    * summmed = true: then the function returns (in seconds) the total volume/time in this interval, else returns time (in seconds) of each interval.\n",
      "timebase = 'seconds', not changable atm!\n",
      "    CF_ts_to_s, Timeseries for Water in pl-units is in min [l/min]. Since integration interval is in SECONDS values => CF =1/60. Change for other units\n",
      "   \n",
      "    #todo:\n",
      "    # merge with time_in_interval\n",
      "    #speed up calculation\n",
      "    \"\"\"\n",
      "    \n",
      "    #df_reindexed = pd.DataFrame(data=series.values, index=range(0,len(series))) #assuming data is equally spaced, time =minute.\n",
      "    #todo: make calculations on date objects\n",
      "    posLc,tsLc = cross(series, LimLow, 'cross')\n",
      "    posHc,tsHc = cross(series, LimHigh, 'cross')\n",
      "    \n",
      "        #into\n",
      "    posLr,tsLr = cross(series, LimLow, 'rising')\n",
      "    posHf,tsHf = cross(series, LimHigh, 'falling')\n",
      "    ts_into =  tscombine(tsHf,tsLr)\n",
      "    dt_in = ts_into.index\n",
      "    #out\n",
      "    posHr,tsHr = cross(series, LimHigh, 'rising')\n",
      "    posLf,tsLf = cross(series, LimLow, 'falling')\n",
      "    ts_out =  tscombine(tsHr,tsLf)\n",
      "    dt_out = ts_out.index\n",
      "    \n",
      "    #print(crossposLf,n_time_occ)\n",
      "    cross_ts = tscombine(tsHc,tsLc)\n",
      "    crossings = cross_ts.index\n",
      "    # combine crossings and series\n",
      "    series_with_crossing = tscombine(cross_ts,series)\n",
      "    #df_combined=pd.concat([series, cross_ts], axis=1)\n",
      "    #series_with_crossing = df_combined[0].dropna()\n",
      "\n",
      "    interval_lengths = np.zeros([len(series_with_crossing)-1])\n",
      "    if 1 ==1:\n",
      "        if len(crossings)>0:\n",
      "            for i in arange(0, len(series_with_crossing)-1):\n",
      "                tdelta = series_with_crossing.index[i+1]-series_with_crossing.index[i] # in seconds and days.\n",
      "                try:\n",
      "                    interval_lengths[i]=( tdelta.seconds +tdelta.days*24*60*60) # tdelta_in_ seconds\n",
      "                except:\n",
      "                    print i, type(tdelta)\n",
      "            #print len(interval_lengths),min(interval_lengths),max(interval_lengths)\n",
      "            # integrate over time (assumed in MINUTES)\n",
      "            ts_timeintegrated = pd.TimeSeries(data= series_with_crossing.values[0:-1]* CF_ts_to_s *interval_lengths ,\n",
      "                                              index = series_with_crossing.index[0:-1])\n",
      "            #apply cusum and diff\n",
      "            cumsum = ts_timeintegrated.cumsum()\n",
      "            cumul_vols_atcrossing = cumsum[crossings[:]]\n",
      "            volumes_tot = cumul_vols_atcrossing.diff()\n",
      "            #print type(volumes_tot), cumul_vols_atcrossing\n",
      "            #print posLr,posHr,posLf,posHF\n",
      "            if (posLr[0] == posHr[0])|(posLf[0] == posHf[0]):\n",
      "                #both outside/on boundary =>\n",
      "                volumes = [0]       \n",
      "            \n",
      "            elif ((crossings[0] == posLr[0])| (crossings[0] == posHf[0])):\n",
      "                #print 'case A'\n",
      "                #series started below LowLim interval, thus keep all diff.\n",
      "\n",
      "                \n",
      "                lmin = min(len(ts_into),len(ts_out))*2-2\n",
      "                volumes = volumes_tot.values[1:lmin:2]\n",
      "            elif ((crossings[0] == posLf[0]) |(crossings[0] == posHr[0])): \n",
      "                #print 'case B'\n",
      "                #series started inside interval, thus drop first of into (and maybe last)\n",
      "                lmin = min(len(ts_into),len(ts_out)-1)*2-4\n",
      "        \n",
      "                volumes = volumes_tot.values[1:lmin:2]\n",
      "        else:  #if no crossing \n",
      "            return [0]\n",
      "    if summed==False:\n",
      "        return volumes\n",
      "    else:\n",
      "        return round(np.nansum(volumes,axis=0),2)\n",
      "\n",
      "# Short Example \n",
      "# Give time interval length (time) each time the data is in tapping interval:\n",
      "LL = 10\n",
      "LH = 20\n",
      "Tresh = 60\n",
      "vol  = volume_in_interval(example_series, LimLow = LL,LimHigh = LH, TH_time =  Tresh)\n",
      "print 'Time-integrated impact of each tapping occurence between the intervals lasting longer than ',Tresh,'seconds, in [l == l/min* (sec/min*60)]:'\n",
      "print vol\n",
      "\n",
      "total_vol = volume_in_interval(example_series, LimLow = LL,LimHigh = LH,\n",
      "                                     TH_time = 0, summed = True, plottoo=False)\n",
      "print 'Total impact of between the intervals over whole horizon, in [l == l/min* (sec/min*60)]:'\n",
      "print total_vol\n",
      "print 'cost:' ,total_vol/1000. * units.get_conversionfactor(utility,fromref='int',fromusage='si',toref='int', tousage='cost'), '\u20ac'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadcurve_simple(ts,label=None,ylabel=None,xlabel =None, pct=0):\n",
      "\n",
      "    # Load-Curve plot\n",
      "    # propose to add this to plotting library\n",
      "    if label ==None:\n",
      "        label ={'Load curve of timeseries'}\n",
      "    if ylabel ==None:\n",
      "        ylabel ='Utility usage, sorted by intensity'\n",
      "    if xlabel ==None:\n",
      "        xlabel = 'Time '\n",
      "        \n",
      "    LCfig = plt.figure()\n",
      "    #should include a resample, normally!!\n",
      "    loadcurvedata = np.sort(np.nan_to_num(ts.values))[::-1]\n",
      "\n",
      "    #all data on graph, just some zooming to interesting area. can be moved to input or removed\n",
      "    \n",
      "    y_min_index = np.floor(len(loadcurvedata)*pct/100.)\n",
      "    y_max_index = np.floor(len(loadcurvedata)*(100-pct)/100.)-1 # cut out nans & zeros/low values\n",
      "    LCD_toplot = loadcurvedata\n",
      "    plt.plot(LCD_toplot)\n",
      "    plt.ylim([  loadcurvedata[y_max_index],  loadcurvedata[y_min_index] ])\n",
      "    plt.xlabel(xlabel)\n",
      "    plt.ylabel(ylabel)\n",
      "    #plt.xscale('log')\n",
      "    #plt.xlabel('log of time step')\n",
      "    plt.legend(label)\n",
      "    plt.show()\n",
      "    plt.xlabel\n",
      "    return loadcurvedata #np.array\n",
      "    \n",
      "#small example\n",
      "label = {FL}\n",
      "lcdata =loadcurve_simple(example_series,pct=0)\n",
      "print lcdata[1:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadcurve_advanced(ts,incl_der=False,TH_low = 0,plotit=True,logx = False, logy=False): \n",
      "    unsorted =ts.values\n",
      "    #TH_low cutoff at xx l/min\n",
      "\n",
      "    # TODO: let it accept list of DF instead of single series.\n",
      "    if True:\n",
      "        sorted = np.sort(unsorted,0)\n",
      "        JBDC = sorted[::-1] ;\n",
      "        above_TH = (JBDC>TH_low)\n",
      "        nans  = np.isnan(JBDC)\n",
      "        filtered = (~nans) * above_TH\n",
      "        #print np.count_nonzero(filtered)\n",
      "        JBDCNonan = JBDC[filtered]\n",
      "        logJBCD = np.log(JBDCNonan)\n",
      "        firstder = np.diff(JBDCNonan ,n=1,axis=0)\n",
      "        secondder =np.diff( JBDCNonan,n=2,axis=0 )  #alternative: use pd.diff http://stackoverflow.com/questions/13689512/numpy-diff-on-a-pandas-series\n",
      "        \n",
      "        fig,ax = plt.subplots() \n",
      "        if (plotit):\n",
      "        #    ax1 = plt.plot(JBDCNonn)\n",
      "        #elif (incl_der)*(plotit):\n",
      "            if logy:\n",
      "                ax1= plt.plot(logJBCD,'b')\n",
      "            else:\n",
      "                ax1= plt.plot(JBDCNonan,'b')\n",
      "            if (incl_der):\n",
      "                plt.hold(True)\n",
      "                ax1= plt.plot(firstder,'g')\n",
      "                ax1= plt.plot(secondder,'r')\n",
      "            if logx:\n",
      "                plt.hold(True)\n",
      "                ax.set_yscale('log')               \n",
      "                plt.xlabel('time')\n",
      "                plt.ylabel('water draw [l/min] (log) and  water draw derivative [l/min^2]')\n",
      "            \n",
      "                # todo: add labels, header, etc.\n",
      "            plt.hold(False)\n",
      "            # i used log, otherwise large peaks compared to der. 2 = 1E2 = 100, etc \n",
      "            #jbdc gives intensity (l/min) vs time (minutes!) in a sorted manner             \n",
      "        else:\n",
      "            a=1\n",
      "\n",
      "    #return len(JBDCNonan), len(firstder), len(secondder)\n",
      "\n",
      "# Example:\n",
      "loadcurve_advanced(example_series,TH_low=0.4,plotit=True,incl_der=True,logx=False,logy=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Example time!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ways to visualise the raw data: (carpet, timechart and JBDC)\n",
      "print FL\n",
      "fig = plt.figure()\n",
      "plt.plot(example_series.index, example_series)\n",
      "plt.xlabel('Date')\n",
      "plt.ylabel(\"{}-usage [{}]\".format(utility,bUnit))\n",
      "plt.legend([FL]) \n",
      "\n",
      "from carpetplot.library import plotting\n",
      "plotting.carpet(example_series)\n",
      "\n",
      "loadcurve_simple(example_series,{FL})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def piechart(data,piecelabels=None,legendlabels=None,xlabel=None,ylabel=None,title=None,**kwargs):\n",
      "    '''propose to add to plotting library\n",
      "    '''\n",
      "    fig =figure()\n",
      "    ax1 = subplot(1,1,1)\n",
      "    matplotlib.pyplot.pie(data,labels = piecelabels, autopct='%1.f%%', shadow=True, startangle=90,**kwargs)                \n",
      "    ax1.set_title(title)\n",
      "    ax1.set_ylabel(ylabel)\n",
      "    ax1.legend(legendlabels,'best')\n",
      "\n",
      "#example:\n",
      "#*piecelabels = labels_h\n",
      "data = [2,4,10,12,10,20]\n",
      "piecelabels= {'A','B','C','D','E','F'}\n",
      "legendlabels=  {'moreinfohere on A', 'moreonB', 'yougetthepoint', 'Dvalue = 4','E','F'}# {'A longer explanation, better overview/comparison\n",
      "yaxislable = 'random example'\n",
      "FL = hp.get_flukso_from_sensor(sensor)\n",
      "piechart(data,piecelabels=piecelabels,legendlabels=legendlabels,title=FL,ylabel=yaxislable)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Example on using volume intervals in scatter plot: \n",
      "#Not very fast, takes about 4 seconds for 5 bins and 14 days...\n",
      "\n",
      "ts = example_series\n",
      "lims = np.arange(0,15,5)\n",
      "# input = timeseries, and no bins are given, 10 bins between min and max are assumed\n",
      "tIntUnits = units.get_units(util,usage='pl',ref='int')\n",
      "\n",
      "figure()\n",
      "ax1 = subplot(1,1,1)\n",
      "plt.hold(True)\n",
      "\n",
      "for i in range(1,len(lims)):\n",
      "\n",
      "    times = time_in_interval(ts, LimLow = lims[i-1],LimHigh = lims[i], TH_time = 0)/3600. #in hours\n",
      "    volumes  = volume_in_interval(ts, LimLow = lims[i-1],LimHigh = lims[i], TH_time = 0) # in liter\n",
      "    #nocc = occurence_in_bin(example_series, LimLow = lims[i-1],LimHigh = lims[i]) \n",
      "    #better save the data in a df/ts! (but I'm a bit clumpsy with that)\n",
      "    #WIP\n",
      "    times.name =\"\".join([str(lim[i-1]), 'to',str(lim[i]),'l'])\n",
      "    volumes.name ='volumes'\n",
      "    if i ==1:\n",
      "        times_DF= pd.DataFrame(data=times,index=lims[i-1], axis=1\n",
      "    else: #TODO: add other data to this df\n",
      "        times_DF = times_DF.concat(data=times,index=lims[i-1], axis=1)\n",
      "        volumes_DF = times_DF.concat(data=volumes,index=lims[i-1], axis=1)\n",
      "        print data_per_bin.describe()\n",
      "    '''\n",
      "\n",
      "    #plt.scatter3(interval_durations,interval_volumes,nocc)\n",
      "\n",
      "    plt.hold(True)\n",
      "    if len(times)==len(volumes):\n",
      "        colours = ['b','r','g']\n",
      "        ax1.scatter(times,volumes,c=colours[i])\n",
      "    else:al\n",
      "        print i, lims[i-1],lims[i]\n",
      "    #ax1.title(\" \".join([FL,utility,'usage']))\n",
      "    plt.xscale('log')\n",
      "    plt.yscale('log')\n",
      "\n",
      "\n",
      "plt.xlabel(\"\".join(['duration of interval [log(minutes)]']))\n",
      "plt.ylabel(\"\".join(['Used volume per interval [liter]']))\n",
      "#plt.zlabel('number of intervals (l)')\n",
      "plt.hold(False)\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binPies(ts,lims =None,legend = None, labels_h = None,labels_v=None,unit_v_int='l',unit_v_base= 'l/min',TH=0,**kwargs):\n",
      "    \"\"\"\n",
      "    Goal: Visualise binned total times and quantities in a pie chart, from one timeseries of the utility usage (default:water) \n",
      "    for multiple days (e.g. showers, baths, toilet, etc)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    * ts : a pandas TimeSeries\n",
      "      One timeseris per sensor\n",
      "    * lims: list of limits. Currently: HAS to be len 7 or less (6 bins max) -due to color selection-\n",
      "        default = np.array([0,0.05,2,4,8,12,1000])\n",
      "    * TH = Treshold of time in seconds, which data should be ignored\n",
      "\n",
      "\n",
      "    OUTPUT: \n",
      "    2 pie-charts per ts, showing time per bin (hr), and volume per bin (liter)\n",
      "\n",
      "    TODO:\n",
      "    * Expand code to allow for more/other nr of bins. Now 6bins  or lower (due to custom colours). will be solved by colorfest library\n",
      "    --------------------------------------------------\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    None\n",
      "    author: Ryton\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\" 6 default bins (7 limits): usage of in each bin given (% of time & % of impact).\"\"\"\n",
      "    \n",
      "    if (lims == None) & (legend == None):\n",
      "        default_wlegend = {\n",
      "        'XL: 12-20 l/min (e.g.shower, bath, pool)',\n",
      "         'L: 8-12 l/min (e.g.large cooking, cleaning)',\n",
      "         'M: 4-8 l/min (e.g.typical toilet)',\n",
      "         'S: 2-4 l/min (e.g.wash hands, cooking)',\n",
      "         'XS: 0.05-2 l/min (extra small draws)',\n",
      "         'XS: 0-0.05 l/min (drip usage (or aliasing)'}\n",
      "        legend = default_wlegend\n",
      "    else:\n",
      "        legend = custom_legend\n",
      "    if lims == None:\n",
      "        lims = np.array([0,0.05,2,4,8,12,1000])\n",
      "    if labels_v ==None:\n",
      "        labels_v = [' 0-bin          ','XS-bin          ',' S-bin          ',' M-bin          ',' L-bin          ','XL-bin          ']\n",
      "    if labels_h == None:\n",
      "        labels_h = '0','XS','S','M','L','XL'\n",
      "    j = 0\n",
      "    if 1 ==1:\n",
      "    #for sensor in sensor: # for each flukso: for sensor in  df_all.columns\n",
      "        FL = ts.name\n",
      "        #ts = df[sensor] #l/min \n",
      "        all_n = []\n",
      "        all_t = []\n",
      "        all_v = []\n",
      "        for i in arange(1,len(lims)):\n",
      "            times = time_in_interval(ts, LimLow = lims[i-1],LimHigh = lims[i],summed=True,TH_time=TH)/3600. #in hours\n",
      "            volumes  = volume_in_interval(ts, LimLow = lims[i-1],LimHigh = lims[i],summed=True,TH_time=TH) # in liter\n",
      "            nocc = occurence_in_bin(ts, LimLow = lims[i-1],LimHigh = lims[i])\n",
      "            #print  i, times, volumes, nocc\n",
      "            all_t = np.append(all_t,times)\n",
      "            all_v = np.append(all_v,volumes)\n",
      "            all_n = np.append(all_n,nocc)\n",
      "        #calculate fractions info\n",
      "        n_data_fr = np.array(all_n*100/all_n.sum())  \n",
      "        v_data_fr = np.array(all_v*100/all_v.sum())\n",
      "        t_data_fr = np.array(all_t*100/all_t.sum())\n",
      "        \n",
      "        \n",
      "        if (n_data_fr[0]!=0): #only if data available\n",
      "            #make volume carpet plot\n",
      "            #create lable & legend\n",
      "            labels_v_old = '0v','Sv','Lv','Mv','MLv','XLv'\n",
      "            labels_range =np.array(labels_h)\n",
      "            labels_vol =np.array(labels_v)\n",
      "            for i in range(1,len(lims)):\n",
      "                \"inrun= [str(lims[i]), 'l/min <=', labels_v[i],'<' ,str(lims[i+1]), 'l/min']\"\n",
      "                inrun_range= [labels_h[i-1],str(lims[i-1]), 'to',str(lims[i]), unit_v_base]; \"labels_h[i], \"\n",
      "                inrun_vol=[\"{0:10.0f}\".format(all_v[i-1]), unit_v_int] # /1 since 1 l/min vs min before\n",
      "                labels_vol[i-1] = ' '.join(inrun_vol)\n",
      "                labels_range[i-1] = ' '.join(inrun_range)\n",
      "            \"print labels_range\"\n",
      "                        \n",
      "            colors = ['grey','yellowgreen', 'gold', 'lightskyblue', 'lightcoral', 'red']        \n",
      "                    \n",
      "            fig = plt.figure(figsize=(20,5))\n",
      "            \n",
      "            \n",
      "            \"hourly impact (pie chart)\"\n",
      "            ax1=fig.add_subplot(141)\n",
      "            title_pie_hour =' '.join(['LENGTH per bin [%h]. (Total:', \"{0:2.0f}\".format(float(all_n.sum())*60) ,'hr)'])\n",
      "            ax1.set_title(FL)\n",
      "            \"ax1.set_title(title_pie_hour)\"\n",
      "            ind =  np.arange(lims.size-1)\n",
      "            width = 0.5\n",
      "            ax1.pie(np.nan_to_num(n_data_fr), labels = labels_h, colors = colors,autopct='%1.f%%', shadow=True, startangle=90,**kwargs)            \n",
      "            ax1.set_xlabel(FL)        \n",
      "            \"\"\"ax1.bar(ind, np.nan_to_num(all_bn)/60, width)\n",
      "            ax1.set_xticks(ind+width)\n",
      "            ax1.set_xticklabels( (labels_h) )\n",
      "            ax1.set_ylabel('Water usage per bin (hours)')\"\"\"\n",
      "            ax1.legend(legend,'best')\n",
      "        \n",
      "            \n",
      "            ax3=fig.add_subplot(142)\n",
      "            title_pie_vol =' '.join([' (integr.) QTY per bin: ', \"{0:5.0f}\".format(float(all_v.sum())) ,' l. Vol% division:'])\n",
      "            'ax3.set_title(title_pie_vol)  '\n",
      "            ax3.set_title(title_pie_vol)\n",
      "            patches = ax3.pie(np.nan_to_num(v_data_fr), labels = labels_v, colors = colors,autopct='%1.f%%', shadow=True, startangle=90,**kwargs)\n",
      "            xlabel_vol =' '.join(['Vol. impact [v%]. Tot. cons: ', \"{0:5.0f}\".format(float(all_v.sum())) ,' l. Vol% division:'])\n",
      "            ax3.set_xlabel(xlabel_vol)        \n",
      "            \"\"\"ax3.legend(patches, labels_v, loc=\"best\")\n",
      "            ax3.axis('equal')\n",
      "            ax3.tight_layout()\"\"\"\n",
      "            \n",
      "            \n",
      "\n",
      "#example\n",
      "print 'Default usage:'\n",
      "binPies(example_series)\n",
      "\n",
      "'customisation possible'\n",
      "custom_lim =np.array([0,4,8,16,20])\n",
      "custom_legend=['bin1','bin2','bin3','bin4']\n",
      "custom_labels_h = ['A','B','C','D',]\n",
      "custom_labels_v = ['Avol','Bvol','Cvol','Dvol']\n",
      "binPies(example_series,lims=custom_lim,legend=custom_legend,labels_h=custom_labels_h,labels_v=custom_labels_v,TH =0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#TODO:\n",
      "#add insights from Jorgan Vayes, 2005, \"Program to generate hot water draws with statistical means.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bin_scatter(ts, lims=[0,0.05,2,4,8,12,1000],binned =True, plot=True ,  TH = 30):\n",
      "    '''\n",
      "    Gives correlation (length vs time) of each bin(binned = True), or individual water draws (binned = False).\n",
      "            \n",
      "    '''    \n",
      "    FL = ts.name\n",
      "    all_n = []\n",
      "    all_t = []\n",
      "    all_v = []\n",
      "    aver_t = [] #average time per water draw per bin, in MINUTES\n",
      "    aver_v = [] #average volume  per water draw per bin\n",
      "    aver_i = [] #average water draw (l/min) per bin\n",
      "    \n",
      "    if binned== False: # plot all (volumes/times)\n",
      "        #ts = df[sensor] #l/min \n",
      "        \n",
      "        for i in arange(1,len(lims)):            \n",
      "            times = time_in_interval(ts, LimLow = lims[i-1],LimHigh = lims[i],summed=False,TH_time=TH) #in seconds\n",
      "            volumes  = volume_in_interval(ts, LimLow = lims[i-1],LimHigh = lims[i],summed=False,TH_time=TH) # in liter\n",
      "            nocc = occurence_in_bin(ts, LimLow = lims[i-1],LimHigh = lims[i])\n",
      "            #print  i, times, volumes, nocc\n",
      "            all_t = np.append(all_t,times)# >1 elements per bin\n",
      "            all_v = np.append(all_v,volumes) # >1 elements per bin\n",
      "            all_n = np.append(all_n,nocc)   #1 element per bin\n",
      "            \n",
      "        #print all_t/60.,all_v, all_n\n",
      "            if binned ==False: #if binning=false\n",
      "                if plot == True:\n",
      "                    plt.hold(True)\n",
      "                    colors = ['grey','yellowgreen', 'gold', 'lightskyblue', 'lightcoral', 'red']        \n",
      "                    fig = figure()\n",
      "                    sctr = subplot(1,1,1)\n",
      "                    sc_onebin = plt.scatter(np.divide(volumes,times),times,c=colors[i])\n",
      "        #out of for loop\n",
      "\n",
      "\n",
      "    else: # binned = True\n",
      "        for i in arange(1,len(lims)):            \n",
      "            times = time_in_interval(ts, LimLow = lims[i-1],LimHigh = lims[i],summed=True,TH_time=TH) #in seconds\n",
      "            volumes  = volume_in_interval(ts, LimLow = lims[i-1],LimHigh = lims[i],summed=True,TH_time=TH) # in liter\n",
      "            nocc = occurence_in_bin(ts, LimLow = lims[i-1],LimHigh = lims[i])\n",
      "            #print  i, times, volumes, nocc\n",
      "            all_t = np.append(all_t,times)\n",
      "            all_v = np.append(all_v,volumes)\n",
      "            all_n = np.append(all_n,nocc)   \n",
      "            \n",
      "        #out of loop\n",
      "        aver_t = np.divide(all_t/60.,all_n) #average time per water draw per bin, in MINUTES\n",
      "        aver_v = np.divide(all_v,all_n) #average volume  per water draw per bin\n",
      "        aver_i = np.divide(all_v,aver_t) #average water draw (l/min) per bi\n",
      "        print aver_t,aver_v, aver_i\n",
      "        if plot == True:\n",
      "            colors = ['grey','yellowgreen', 'gold', 'lightskyblue', 'lightcoral', 'red']        \n",
      "            fig = figure()\n",
      "            sctr = subplot(1,1,1)\n",
      "            title_binned = 'Water draw intensity (l/min) vs water draw duration (min) (log scale) per bin'\n",
      "            xlab_binned ='Average duration (minutes) of water draw per bin'\n",
      "            ylab_binned ='Average water draw intensity (l/min) per bin'\n",
      "            sc_perbin = plt.scatter(aver_v,aver_t)\n",
      "            '''\n",
      "            TODO: make graph prettier/add labels/title/etc\n",
      "            sctr.set_xscale('log')\n",
      "            sctr.xlabel(xlab_binned)\n",
      "            sctr.ylabel(ylab_binned)\n",
      "            sctr.set_title(title_binned)\n",
      "            '''\n",
      "    #    return aver_t,aver_v,aver_i\n",
      "    return all_t,all_t,all_n # raw values per bin or per occurence\n",
      "\n",
      "#short example\n",
      "bin_scatter(example_series)\n",
      "#bin_scatter(example_series, binned=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " A = [ 511.97,         15.69753846  , 10.89139535,30.88088889 ,  78.19294118,\n",
      "  388.282     ]\n",
      "B =    [  0.56462868 , 10.17727832 , 14.0487565  ,  8.30252659 ,  2.99740155,\n",
      "   0.76870172]\n",
      "# scatter(A,B)\n",
      "title_binned = 'Water draw intensity (l/min) vs water draw duration (min) (log scale) per bin'\n",
      "xlab_binned ='Average duration (minutes) of water draw per bin'\n",
      "ylab_binned ='Average water draw intensity (l/min) per bin'\n",
      "sc_perbin = plt.scatter(aver_v,aver_t)\n",
      "sc_perbin.set_xscale('log')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "            #yticks(range(0, max(aver_cons_per_bin/60/24).all, 5))            \n",
      "'''\n",
      "            \"histogram per bin\"\n",
      "            # def hist_duration_per_bin(\n",
      "            for i in range(1,len(lims)):\n",
      "                if lims[i] > 0.5:\n",
      "                    step = 0.25\n",
      "                else:\n",
      "                    step = 0.05\n",
      "                in_bin_limits = np.arange(lims[i-1],lims[i],step)\n",
      "                all_bv,lims2 = np.histogram(input_vector,lims,weights=input_vector) #volume (l)  per bin (l/min range)\n",
      "            #WIP\n",
      "            #water_usage_lengths= length_WUsage(series,hp, Lim_Low = 0.1,LimHigh = 1000, averaged = False):\n",
      "            #figure()\n",
      "            #plot(water_usage_lengths,color) #color based on label of bin. => combine in piechart graph.\n",
      "'''\n",
      "            \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}