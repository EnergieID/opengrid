{
 "metadata": {
  "name": "",
  "signature": "sha256:008a6ade103d7898e061cba8fb06896e3a43e9577268d3f902894dab50491c40"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## This script shows how to make some usage profile comparisons (mainly against own historic utility usage)\n",
      "For this purpose, \n",
      "A) a load_duration_curve (JBDC) is shown, \n",
      "B) Utility usage frequency, length, and intensity are calculated,and shown in scatter plots\n",
      "C) Pie charts are used to evaluate the relative impact of each bin (grouped per intensity)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# some imports & opengridCC setup\n",
      "\n",
      "import os, sys\n",
      "import inspect\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from matplotlib.dates import HourLocator, DateFormatter\n",
      "import datetime as dt\n",
      "import pytz\n",
      "BXL = pytz.timezone('Europe/Brussels')\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "\n",
      "script_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
      "# add the path to opengrid to sys.path\n",
      "sys.path.append(os.path.join(script_dir, os.pardir, os.pardir))\n",
      "from opengrid.library import config\n",
      "from opengrid.library import houseprint\n",
      "from opengrid.library import fluksoapi\n",
      "import pytz\n",
      "c = config.Config()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Script settings"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize']=14,8\n",
      "path_to_data = c.get('data', 'folder')\n",
      "#path_to_data = 'SET_CUSTOM_PATH_HERE'\n",
      "\n",
      "if not os.path.exists(path_to_data):\n",
      "    raise IOError(\"Provide your path to the data.  This is a folder containing a 'zip' and 'csv' subfolder.\")\n",
      "else:\n",
      "    path_to_csv = os.path.join(path_to_data, 'csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chosen_type = 0\n",
      "#  0 =water, 1 = gas, 2 = electricity : choose your type of analysis.\n",
      "\n",
      "\n",
      "#default values:\n",
      "UtilityTypes = ['water', 'gas','electricity'] # {'water','gas','electricity'} \n",
      "utility =  UtilityTypes[chosen_type] # here 'electricity'\n",
      "FL_units = ['l/day', 'm^3/day ~ 10 kWh/day','Ws/day'] #TODO, to be checked!!\n",
      "Base_Units = ['l/min', 'kW','kW']\n",
      "Base_Corr = [1/24.0/60.0, 1/100.0/24.0/3.600 , 3.600/1000.0/24 ] #TODO,check validity of conversions!! # water => (l/day) to (l/hr), gas: (l/day) to (kW), elektr Ws/d to kW\n",
      "\n",
      "tInt_Units = ['l', 'kWh','kWh'] #units after integration\n",
      "tInt_Corr = [1/60, 3600/60, 3600/60] #TODO, to be checked!! # water => (l/hr) to (l_cumul/min), gas: kW to (kWh/min)\n",
      "\n",
      "# units for this utility type\n",
      "bUnit = Base_Units[chosen_type]\n",
      "bCorr = Base_Corr[chosen_type]\n",
      "fl_unit = FL_units[chosen_type]\n",
      "tiUnit = tInt_Units[chosen_type]\n",
      "tiCorr = tInt_Corr[chosen_type]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### We create a list with dataframes convert it to more usefull units.\n",
      "Each dataframe contains all utility consumption data we have available.\n",
      "Then it is filtered to a specific time period and filtered to one example series (one fluksometer)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hp = houseprint.load_houseprint_from_file('hp_anonymous.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load data\n",
      "print 'Loading', utility ,'-data and converting from ',fl_unit ,' to ',bUnit,':'\n",
      "dataframes = []\n",
      "sensors = hp.get_sensors_by_type(utility)\n",
      "for sensor in sensors:\n",
      "    FL =hp.get_flukso_from_sensor(sensor)\n",
      "    csv = fluksoapi.find_csv(path_to_csv, sensor)\n",
      "    if len(csv) <> 0:\n",
      "        data=fluksoapi.load_csv(csv)\n",
      "        if len(data)>0:\n",
      "            dataframes.append(data)\n",
      "            #print FL, ' loaded correctly with sensor', data.columns[0]\n",
      "    #else:\n",
      "            #print FL, sensor, 'not loaded\n",
      "print('{} {}-sensors loaded.'.format(len(dataframes),utility))\n",
      "\n",
      "#dataframes = list of dataframes\n",
      "df = dataframes[0].join(dataframes[1:], how='outer')\n",
      "\n",
      "# remove null columns\n",
      "df.dropna(axis=1, how='all', inplace=True)\n",
      "print('{} Sensors with data retained'.format(len(df.columns))) \n",
      "\n",
      "# convert the dataframe to LOCAL TIME (BRUSSELS)\n",
      "df.index = df.index.tz_convert(pytz.timezone('Europe/Brussels'))\n",
      "#df is a joined pandas dataframe\n",
      "\n",
      "# conversion dependent on type of utility (to be checked!!) \n",
      "df = df*bCorr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#example: plot data of 1 sensor, specific time period:\n",
      "sensors = hp.get_sensors_by_type(utility)\n",
      "sensor=sensors[1]\n",
      "from_date = pd.datetime.today()-dt.timedelta(days=30)\n",
      "to_date = pd.datetime.today()-dt.timedelta(days=1)\n",
      "FL = hp.get_flukso_from_sensor(sensor) \n",
      "\n",
      "#output used in rest of script:\n",
      "example_series =df.ix[from_date:to_date][sensor]\n",
      "smaller_df =df.ix[from_date:to_date]\n",
      "\n",
      "print FL\n",
      "fig = plt.figure()\n",
      "plt.plot(example_series.index, example_series)\n",
      "plt.xlabel('Date')\n",
      "plt.ylabel(\"{}-usage [{}]\".format(utility,bUnit))\n",
      "plt.legend([FL]) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Below, several new subfunctions are shown (cross,values_in_bin, tapping_intervals, and  Pie_WUsage)\n",
      "#### Example code for each subfunction is always right below the function (commented out with #)\n",
      "\n",
      "#### Each script (aside from the Pie_chart) uses a single time series (example_series), which can be any \"water, gas or elec\" usage timeseries, ####but the analysis is designed for /makes most sense for <bold>water data.</bold>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross(series, cross=0, direction='cross'):\n",
      "    \"\"\"\n",
      "    Given a Series, this function returns all the index values where the data values equal \n",
      "    the 'cross' value. \n",
      "\n",
      "    Direction can be 'rising' (for rising edge), 'falling' (for only falling \n",
      "    edge), or 'cross' for both edges\n",
      "    author: Daylyglen:\n",
      "    url: http://stackoverflow.com/questions/10475488/calculating-crossing-intercept-points-of-a-series-or-dataframe\n",
      "    \"\"\"\n",
      "    # Find if values are above or bellow yvalue crossing:\n",
      "    above=series.values > cross\n",
      "    below=np.logical_not(above)\n",
      "    left_shifted_above = above[1:]\n",
      "    left_shifted_below = below[1:]\n",
      "    x_crossings = []\n",
      "    # Find indexes on left side of crossing point\n",
      "    if direction == 'rising':\n",
      "        idxs = (left_shifted_above & below[0:-1]).nonzero()[0]\n",
      "    elif direction == 'falling':\n",
      "        idxs = (left_shifted_below & above[0:-1]).nonzero()[0]\n",
      "    else:\n",
      "        rising = left_shifted_above & below[0:-1]\n",
      "        falling = left_shifted_below & above[0:-1]\n",
      "        idxs = (rising | falling).nonzero()[0]\n",
      "\n",
      "    # Calculate x crossings with interpolation using formula for a line:\n",
      "    x1 = series.index.values[idxs]\n",
      "    x2 = series.index.values[idxs+1]\n",
      "    y1 = series.values[idxs]\n",
      "    y2 = series.values[idxs+1]\n",
      "    x_crossings = (cross-y1)*(x2-x1)/(y2-y1) + x1\n",
      "\n",
      "    return x_crossings\n",
      "#example\n",
      "crosswhere = cross(example_series, cross=4, direction='cross') #cross = 4 = 4l/min\n",
      "crossDateTime=pd.TimeSeries(index=crosswhere)\n",
      "print crossDateTime.index[1], type(crossDateTime.index[1])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def values_in_bin(series, LimLow = 8 , LimHigh = 1000):\n",
      "    \"\"\"\n",
      "    *series: pandas timeseries (1x n vector)\n",
      "    * Lim low = lower limit of checking, in l/min # * *60*24?\n",
      "    * Upper limit in l/min. can be +inf\n",
      "    \n",
      "        output: number of crossings above lim low, but below lim-hihg (thus summed time of water usages (minutes) in a specific bin.\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "    #df_reindexed_t = pd.DataFrame(data=series.values, index=range(0,df_all.shape[0]))\n",
      "    crossposLr = cross(series, LimLow, 'rising')\n",
      "    crossposHf = cross(series, LimHigh, 'falling')\n",
      "    \"print crossposL \"\n",
      "    try:\n",
      "        n_occ =crossposLr.size + crossposHf().size\n",
      "    except:\n",
      "        n_occ = crossposLr.size\n",
      "    return n_occ\n",
      "#example\n",
      "#random_sample = pd.TimeSeries([0,2,3,6,2,4.2,4.5,3,2,1,4,3,0])\n",
      "n_occ = values_in_bin(example_series, LimLow = 10, LimHigh = 15) \n",
      "print n_occ"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tapping_intervals(series,hp, LimLow = 0.1,LimHigh = 1000, TH_time = 0, output = 'times', timescale = 's', averaged = True, plottoo = True):\n",
      "    \"\"\"\n",
      "    Purpose: Gives list of tapping lengths in preferred timescale (e.g. minutes) when the series is between limLow and LimHigh. \n",
      "    Also, integrated volumes per tapping will be available (currently an approximation is made: Average of limit * length of tapping!)\n",
      "    # prev name: length_in_bins or time_in_bins\n",
      "    Inputs:\n",
      "    *series: pandas Dataframe series (1x n vector) (already in default values)\n",
      "    * Lim low = lower limit of checking, in l/min\n",
      "    * Upper limit of checking, in l/min. \n",
      "    * TH_time = if time in interval below this value => def: to 0\n",
      "    * output=  give 'times', \n",
      "    TODO: add correct 'volume calculation (cumulative volume in interval (between crossings)) (WIP)\n",
      "         SOLVE crash if empty data series.\n",
      "         \n",
      "    resident_length of water usage in the range. #timedelta.\n",
      "    average_time: timedelta\n",
      "    timescale = 's', 'h', 'min', to give output in this unit (else nanoseconds...).\n",
      "    \"\"\"\n",
      "   \n",
      "    #df_reindexed = pd.DataFrame(data=series.values, index=range(0,len(series))) #assuming data is equally spaced, time =minute.\n",
      "    #todo: make calculations on date objects\n",
      "    crossPosLc = cross(series, LimLow, 'cross')\n",
      "    crossPosHc = cross(series, LimHigh, 'cross')\n",
      "    #into\n",
      "    crossposLr = cross(series, LimLow, 'rising')\n",
      "    crossposHf = cross(series, LimHigh, 'falling')\n",
      "    #out\n",
      "    crossposHr = cross(series, LimHigh, 'rising')\n",
      "    crossposLf = cross(series, LimLow, 'falling')\n",
      "    #print(crossposLf,n_time_occ)\n",
      "    crossings = []\n",
      "    crossings = np.append(crossPosLc,crossPosHc)\n",
      "    crossings = np.sort(crossings) # datetime format \n",
      "    \n",
      "\n",
      "    problem_solved = False \n",
      "    # # NOT OK (interpolate trows error)\n",
      "    if (output <> 'times'):\n",
      "    #ts_reindexed =   series.resample(crossings)\n",
      "    #ts_cusum = ts_reindexed.cumsum()\n",
      "    #ts_diff = ts_reindexed.dif \n",
      "    #print ts_diff.head()\n",
      "        '''DateTime_cross =   pd.DatetimeIndex(crossings)\n",
      "        #next codeblock contributed by saroele, but failing :'(\n",
      "        # in this cell, we create a pd.DatetimeIndex with datetimes rounded to seconds for the crossing timestamps.\n",
      "        #c = cross(example_series, 5)\n",
      "        not_rounded = pd.DatetimeIndex(DateTime_cross)\n",
      "        rounded = pd.DatetimeIndex(np.round(not_rounded.astype(np.int64), -9).astype('datetime64[ns]'))\n",
      "        crossing_index = rounded.tz_localize(BXL)\n",
      "        # Add the crossing_index to the timeseries by creating a new DataFrame and converting back to TimeSeries \n",
      "        df_combined=pd.concat([series, pd.TimeSeries(index=crossing_index)], axis=1)\n",
      "        series_with_crossing = df_combined[0]\n",
      "        series_with_crossing.name = series.name\n",
      "        print series_with_crossing\n",
      "        series_with_crossing.interpolate(method='time', inplace=True, limit=1)\n",
      "        \n",
      "        ts_cusum = series_with_crossing.cumsum()\n",
      "        ts_values_at_cross = series_with_crossing.ix[crossing_index]\n",
      "        cumul_volumes_at_cross = ts_cusum.ix[crossing_index]\n",
      "        volumes = pd.DataFrame.diff(cumul_volumes_at_cross)\n",
      "        print cumul_volumes_at_cross[1:10]'''\n",
      "        # Now interpolate to get the values at each crossing datetime.  We DON'T interpolate for consecutive NaN values\n",
      "\n",
      "\n",
      "    if len(crossings)>0:\n",
      "        if (crossings[0] <> crossposLr[0]): \n",
      "            #series started inside interval then goes down, thus drop first\n",
      "            resident_length = crossings[2:-1:2]-crossings[1:-2:2]\n",
      "            '''if ((output <> 'times') &  problem_solved==True) :\n",
      "                volumes = ts_diff[1:-1:2]  #always volume in and out, only keep IN interval.'''\n",
      "        elif (crossings[0] == crossposLr[0]):\n",
      "            #series started below interval then goes in, thus keep all.\n",
      "            resident_length = crossings[1:-1:2]-crossings[0:-2:2]        \n",
      "            '''if ((output <> 'times') &  problem_solved==True) :\n",
      "                volumes = ts_diff[0:-1:2] '''\n",
      "        elif (crossings[0] == crossposHf[0]): #could be unexisting\n",
      "            #series started inside interval then goes out above, thus drop first and last\n",
      "            resident_length = crossings[2:-1:2]-crossings[1:-2:2]\n",
      "            '''if (output <> 'times')&  problem_solved==True) :\n",
      "                volumes = ts_diff[1:-2:2] '''\n",
      "        else: \n",
      "            #series started outside interval, thus keep all.\n",
      "            resident_length = crossings[1:-1:2]-crossings[0:-2:2]\n",
      "            '''if ((output <> 'times') &  problem_solved==True ):\n",
      "                \n",
      "                volumes = ts_diff[0:-1:2] '''\n",
      "\n",
      "\n",
      "        \n",
      "        if len(resident_length)>0:\n",
      "            #remove tiny intervals .\n",
      "            resident_length[np.greater_equal(TH_time,resident_length)] = 0  #if TH_time >= reslength => ==0\n",
      "            #print n_time_occ, resident_length\n",
      "            resident_length = pd.to_timedelta(resident_length,unit=timescale)\n",
      "            resident_in_chosen_units = resident_length/ np.timedelta64(1,timescale)\n",
      "            #print size(resident_in_chosen_units)\n",
      "            total_time = np.sum(resident_in_chosen_units.values,axis=0) #sum in chosen units\n",
      "            if (output <> 'times')  :\n",
      "                volumes = (LimLow+LimHigh)/2.0 *  resident_in_chosen_units.values      \n",
      "            n_time_occ = np.count_nonzero(resident_in_chosen_units.values);\n",
      "            aver_time = total_time /float(n_time_occ);\n",
      "        else: #if len(res_length)==0, thus no valid intervals\n",
      "            resident_in_chosen_units =  pd.to_timedelta(0,unit=timescale)\n",
      "            volumes = 0\n",
      "            aver_time = 0\n",
      "    else: #if len(crossings)==0\n",
      "            resident_in_chosen_units =  pd.to_timedelta(0,unit=timescale)\n",
      "            volumes = 0\n",
      "            aver_time = 0\n",
      "        \n",
      "    #print resident_in_chosen_units[1:5]\n",
      "    \n",
      "    #print 'n times:' ,np.int(n_time_occ)\n",
      "    #print aver_time, \"in [{}]!\".format(chosen_timescale)\n",
      "    if plottoo:\n",
      "        FL = hp.get_flukso_from_sensor(sensor)\n",
      "        plt.hist(resident_in_chosen_units)\n",
      "        plt.legend(\"\".join(FL))\n",
      "        plt.xlabel(\"Session length of utility usage between {} and {} {}, in [{}]\".format(LimLow,LimHigh,bUnit,chosen_timescale))\n",
      "        plt.ylabel(\"ulility use frequency [#]\")\n",
      "    \n",
      "    if averaged:    #todo: fix average! \n",
      "        if output <> 'times':\n",
      "            return np.mean(volumes)\n",
      "        else:\n",
      "            return aver_time; \"total average ({});\"\n",
      "    else:\n",
      "        if output <> 'times':\n",
      "            return volumes\n",
      "        else:\n",
      "            return resident_in_chosen_units; 'list of lengths '\n",
      "                    \n",
      "# Examples \n",
      "\n",
      "#Time intervals:\n",
      "chosen_timescale = 'm'\n",
      "resident_length  = tapping_intervals(example_series,hp, LimLow = 10,LimHigh = 15, output ='times',timescale = chosen_timescale, TH_time = 1, averaged = False, plottoo=True)\n",
      "print 'Length of each usage in [',chosen_timescale,']'\n",
      "print resident_length #pd.DataFrame\n",
      "#total_time = np.sum(resident_length.values,axis=0)\n",
      "#print 'Total time in interval:', total_time, chosen_timescale\n",
      "\n",
      "#Volume in intervals:\n",
      "# NOT OK (interpolate trows error) => patch: calculate time from volume\n",
      "vol_output  = tapping_intervals(example_series,hp, LimLow =10,LimHigh = 15, output = 'volume', timescale = 'm',TH_time = 0, averaged = False, plottoo=False)\n",
      "aver_vol  = tapping_intervals(example_series,hp, LimLow =10,LimHigh = 15, output = 'volume', timescale = 'm',TH_time = 1, averaged = True,plottoo=False)\n",
      "\n",
      "print 'Volume per tapping in interval in: [l] [l/min* m].', aver_vol, 'average'\n",
      "print vol_output #np.array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code by saroele,for interpolation at CROSS values (previous cell, VOLUME case)\n",
      "# crashes for Ryton on example_series_with_crossing.interpolate\n",
      "\n",
      "# In this cell, we create a pd.DatetimeIndex with datetimes rounded to seconds for the crossing timestamps.\n",
      "c = cross(example_series, 5)\n",
      "not_rounded = pd.DatetimeIndex(c)\n",
      "rounded = pd.DatetimeIndex(np.round(not_rounded.astype(np.int64), -9).astype('datetime64[ns]'))\n",
      "crossing_index = rounded.tz_localize(BXL)\n",
      "\n",
      "# Add the crossing_index to the timeseries by creating a new DataFrame and converting back to TimeSeries \n",
      "df_n=pd.concat([example_series, pd.TimeSeries(index=crossing_index)], axis=1)\n",
      "example_series_with_crossing = df_n[0]\n",
      "example_series_with_crossing.name = example_series.name\n",
      "\n",
      "# Now interpolate to get the values at each crossing datetime.  We DON'T interpolate for consecutive NaN values\n",
      "print(\"Before interpolation: no values for the crossing_index\")\n",
      "print example_series_with_crossing.ix[crossing_index]\n",
      "example_series_with_crossing.interpolate(method='time', inplace=True, limit=1)\n",
      "print(\"\\nAfter interpolation:\")\n",
      "print example_series_with_crossing.ix[crossing_index]\n",
      "\n",
      "example_series_with_crossing.plot()\n",
      "\n",
      "print crossing_index\n",
      "print example_series.index\n",
      "print df_n.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Example show volume intervals: \n",
      "#NOT OK yet => Quick patch applied to calc volume => not fully accurate\n",
      "chosen_timescale = 'h'\n",
      "lims = np.arange(1,20,0.5)\n",
      "\n",
      "\n",
      "\n",
      "for i in range(1,len(lims)):\n",
      "    tsc_duration = chosen_timescale\n",
      "    \n",
      "    tsc_volume = 'm'\n",
      "    interval_durations  = tapping_intervals(example_series,hp, LimLow = lims[i-1],LimHigh = lims[i], output ='times',timescale = tsc_duration , TH_time = 1, averaged = False, plottoo=False)\n",
      "    interval_volumes  = tapping_intervals(example_series,hp, LimLow = lims[i-1],LimHigh = lims[i],output ='volume',timescale = tsc_volume, TH_time = 1, averaged = False, plottoo=False)\n",
      "    nocc = values_in_bin(example_series, LimLow = lims[i-1],LimHigh = lims[i]) \n",
      "    try:\n",
      "        plt.hold(True)\n",
      "        #plt.scatter3(interval_durations,interval_volumes,nocc)\n",
      "        plt.scatter(interval_durations,interval_volumes)\n",
      "    except:\n",
      "        do_something = False\n",
      "plt.title(\" \".join([FL,utility,'usage']))\n",
      "plt.xscale('log')\n",
      "plt.yscale('log')\n",
      "\n",
      "plt.xlabel(\"\".join(['duration of interval [log(',tsc_duration,')]']))\n",
      "plt.ylabel(\"\".join(['Used volume per interval [', tInt_Units[chosen_type], \"]\"]))\n",
      "#plt.zlabel('number of intervals (l)')\n",
      "plt.hold(False)\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#example time intervals:\n",
      "\n",
      "chosen_timescale = 's'\n",
      "resident_length  = tapping_intervals(example_series,hp, LimLow = 5,LimHigh = 20, output ='times',timescale = chosen_timescale, TH_time = 0, averaged = False, plottoo=True)\n",
      "\n",
      "print 'Length of each usage in [',chosen_timescale,']'\n",
      "print resident_length[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def JBDC(TS,incl_der=False,TH_low = 0,plotit=True,logx = False, logy=False): \n",
      "    unsorted =TS.values\n",
      "    #TH_low cutoff at xx l/min\n",
      "\n",
      "    # TODO: let it accept list of DF instead of single series.\n",
      "    if True:\n",
      "        sorted = np.sort(unsorted,0)\n",
      "        JBDC = sorted[::-1] ;\n",
      "        above_TH = (JBDC>TH_low)\n",
      "        nans  = np.isnan(JBDC)\n",
      "        filtered = (~nans) * above_TH\n",
      "        #print np.count_nonzero(filtered)\n",
      "        JBDCNonan = JBDC[filtered]\n",
      "        logJBCD = np.log(JBDCNonan)\n",
      "        firstder = np.diff(JBDCNonan ,n=1,axis=0)\n",
      "        secondder =np.diff( JBDCNonan,n=2,axis=0 )  #alternative: use pd.diff http://stackoverflow.com/questions/13689512/numpy-diff-on-a-pandas-series\n",
      "        \n",
      "        fig,ax = plt.subplots() \n",
      "        if (plotit):\n",
      "        #    ax1 = plt.plot(JBDCNonn)\n",
      "        #elif (incl_der)*(plotit):\n",
      "            if logy:\n",
      "                ax1= plt.plot(logJBCD,'b')\n",
      "            else:\n",
      "                ax1= plt.plot(JBDCNonan,'b')\n",
      "            if (incl_der):\n",
      "                plt.hold(True)\n",
      "                ax1= plt.plot(firstder,'g')\n",
      "                ax1= plt.plot(secondder,'r')\n",
      "            if logx:\n",
      "                ax.set_yscale('log')               \n",
      "                plt.xlabel('log of time')\n",
      "                plt.xlabel('water draw [l/min]')\n",
      "\n",
      "                # todo: add labels, header, etc.\n",
      "\n",
      "            # i used log, otherwise large peaks compared to der. 2 = 1E2 = 100, etc \n",
      "            #jbdc gives intensity (l/min) vs time (minutes!) in a sorted manner             \n",
      "        else:\n",
      "            a=1\n",
      "\n",
      "    #return len(JBDCNonan), len(firstder), len(secondder)\n",
      "\n",
      "# Example:\n",
      "JBDC(example_series,TH_low=0.4,plotit=True,incl_der=True,logx=False,logy=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Pie_WUsage(df_all, hp,lim =np.array([0,0.001,2,4,8,12,1000]),samebins=False):\n",
      "    \"\"\"\n",
      "    Goal: visualise water usage profiles per FL, in the water consumption for multiple days (e.g. showers, baths, toilet, etc)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    * dataframes : list with pandas DataFrames\n",
      "      One dataframe per sensor\n",
      "    * hp : Houseprint object\n",
      "    * lims: list of limits. curently: has to be len 7\n",
      "    *samebins . true or false. if false, scatter uses 50 bins, else same bins as piechart.\n",
      "    TODO:\n",
      "    * Expand code to allow for more/other nr of bins. Now exactly 6 (len(lim)==7)\n",
      "    * Implement bins on scatter plot too?\n",
      "    * add min-max duration for water draw scatter plot.\n",
      "    * Selection / limitation of time span to analyse\n",
      "    --------------------------------------------------\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Output: 3 plots per FL giving % consumption (hr), liter and correlation (length vs cons) of each bin.\n",
      "    \n",
      "    author: Ryton\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\" 7 default bins: usage of in each bin given (% of time & % of impact).\n",
      "     \n",
      "     20-12 l/min\" (shower,bath, gap)\n",
      "     12-8 l/min\" (large cooking)\n",
      "     8-4 l/min\" (typical toilet)\n",
      "     4-2 l/min\" (wash hands, cooking)\n",
      "     2-0 l/min\" (small draws)\n",
      "    \"\"\"\n",
      "    #TODO:\n",
      "    \n",
      "    #df_all = pd.DataFrame().join(dataframes, how='outer')\n",
      "    #df as input now.\n",
      "    a =dataframes\n",
      "    tl = 60\n",
      "    lims= lim  # limits in l/hr. Maybe better to recalc data to l/min in consistency with other code (all in l/min)\n",
      "  \n",
      "    j = 0\n",
      "    for sensor in df_all.columns: # for each flukso \n",
      "        FL = hp.get_flukso_from_sensor(sensor)\n",
      "        input_vector = np.array(df_all[sensor]) #l/min \n",
      "        all_bn,lims2 = np.histogram(input_vector,lims)  #time (min) per bin (l/min range)\n",
      "        all_bv,lims2 = np.histogram(input_vector,lims,weights=input_vector) #volume (l)  per bin (l/min range)\n",
      "        aver_cons_per_bin = np.divide(all_bv,all_bn)\n",
      "        #n_occ , aver_time_per_bin = calc_bin_properties(input_vector,hp,lim)\n",
      "        n_data_fr = np.array(all_bn*100/all_bn.sum())  \n",
      "        v_data_fr = np.array(all_bv*100/all_bv.sum())\n",
      "        \n",
      "        'print FL, n_data_fr'\n",
      "        if (n_data_fr[0]!=0): #only if data available\n",
      "        \n",
      "            \"create lable & legend\"\n",
      "            labels_v_old = '0v','Sv','Lv','Mv','MLv','XLv'\n",
      "            labels_v = [' 0-bin          ','XS-bin          ',' S-bin          ',' M-bin          ',' L-bin          ','XL-bin          ']\n",
      "            labels_h = '0','XS','S','M','L','XL'\n",
      "            labels_range =np.array(labels_v)\n",
      "            labels_vol =np.array(labels_v)\n",
      "            for i in range(0,6):\n",
      "                \"inrun= [str(lim[i]), 'l/min <=', labels_v[i],'<' ,str(lim[i+1]), 'l/min']\"\n",
      "                inrun_range= [labels_h[i],str(lim[i]), 'to',str(lim[i+1]), 'l/min']; \"labels_h[i], \"\n",
      "                inrun_vol=[\"{0:10.0f}\".format(np.divide(all_bv[i],1)), 'l'] # /1 since 1 l/min vs min . was 60*24 before\n",
      "                labels_vol[i] = ' '.join(inrun_vol)\n",
      "                labels_range[i] = ' '.join(inrun_range)\n",
      "            \"print labels_range\"\n",
      "                        \n",
      "            colors = ['grey','yellowgreen', 'gold', 'lightskyblue', 'lightcoral', 'red']        \n",
      "                    \n",
      "            fig = plt.figure(figsize=(20,5))\n",
      "            \n",
      "            \n",
      "            \"hourly impact (pie chart)\"\n",
      "            ax1=fig.add_subplot(141)\n",
      "            title_pie_hour =' '.join(['Hourly impact [%h]. (Total:', \"{0:2.0f}\".format(float(all_bn.sum())*60) ,'hr)'])\n",
      "            ax1.set_title(FL)\n",
      "            \"ax1.set_title(title_pie_hour)\"\n",
      "            ind =  np.arange(lims2.size-1)\n",
      "            width = 0.5\n",
      "            ax1.pie(np.nan_to_num(n_data_fr), labels = labels_h, colors = colors,autopct='%1.f%%', shadow=True, startangle=90)            \n",
      "            ax1.set_xlabel(title_pie_hour)        \n",
      "            \"\"\"ax1.bar(ind, np.nan_to_num(all_bn)/60, width)\n",
      "            ax1.set_xticks(ind+width)\n",
      "            ax1.set_xticklabels( (labels_h) )\n",
      "            ax1.set_ylabel('Water usage per bin (hours)')\"\"\"\n",
      "            ax1.legend(labels_range,'best')\n",
      "        \n",
      "            \n",
      "            ax3=fig.add_subplot(142)\n",
      "            title_pie_vol =' '.join(['Total consumption: ', \"{0:5.0f}\".format(float(all_bv.sum())) ,' l. Vol% division:'])\n",
      "            'ax3.set_title(title_pie_vol)  '\n",
      "            ax3.set_title(FL)\n",
      "            patches = ax3.pie(np.nan_to_num(v_data_fr), labels = labels_vol, colors = colors,autopct='%1.f%%', shadow=True, startangle=90)\n",
      "            xlabel_vol =' '.join(['Vol. impact [v%]. Tot. cons:', \"{0:5.0f}\".format(float(all_bv.sum())) ,' l. Vol% division:'])\n",
      "            ax3.set_xlabel(xlabel_vol)        \n",
      "            \"\"\"ax3.legend(patches, labels_v, loc=\"best\")\n",
      "            ax3.axis('equal')\n",
      "            ax3.tight_layout()\"\"\"\n",
      "            \n",
      "            #series = [1,2,NaN,5,-12,20]\n",
      "            \n",
      "            \"\"\" jaar belastings duur curve plot.\n",
      "            JBDC(dataframes,incl_der=False,TH_low = 0,plot =False)\n",
      "            not included in this main script\n",
      "            \n",
      "            try:\n",
      "                ax2=plt.subplot(133)\n",
      "                sctr=ax2.scatter(range(N,0,-1),divide(YBDC,60*24))\n",
      "                xlim([0,N])\n",
      "                xticks(range(0, N, 5))\n",
      "            except:\n",
      "                 A = 1\n",
      "            \"\"\"\n",
      "            \n",
      "            \"binned curve (make rectangles later)\"\n",
      "            #lims50 = arange(0,max(input_vector),50)\n",
      "            if not(samebins): #if False;\n",
      "                #make quadratic increasing bins\n",
      "                Nbins = float(50)\n",
      "                one_over_N =divide(1,Nbins)\n",
      "                limn = []\n",
      "                sqr_prt =arange(divide(1,Nbins),1,divide(1,Nbins))* sqrt(max(input_vector))\n",
      "                limn = (sqr_prt*sqr_prt)\n",
      "            else:\n",
      "                limn =lims\n",
      "\n",
      "            all_bnn,lims2 = np.histogram(input_vector,limn)\n",
      "            all_bvn,lims2 = np.histogram(input_vector,limn,weights=input_vector)\n",
      "            aver_cons_n = np.divide(all_bvn,all_bnn)\n",
      "            \n",
      "            ax2=fig.add_subplot(143)\n",
      "            \n",
      "            sctr=ax2.scatter(all_bnn,np.divide(aver_cons_n,1))\n",
      "            ax2.set_title(' Water draw intensity (l/min) vs draw duration (min) (log scale)')\n",
      "            ax2.set_xlabel('Average duration(min) of water draw' )\n",
      "            ax2.set_ylabel('Average water draw intensity (l/min)')\n",
      "            #yticks(range(0, int(yticks()[0][-1])+1, 5))'\n",
      "            plt.ylim([0,max(np.divide(aver_cons_n,1))+0.5])\n",
      "            'xlim([0,max(lims50+10)])'\n",
      "            ax2.set_xscale('log')\n",
      "            'xticks(lims50[])'\n",
      "            #yticks(range(0, max(aver_cons_per_bin/60/24).all, 5))\n",
      "            \n",
      "            \n",
      "            \"histogram per bin\"\n",
      "            # def hist_duration_per_bin(\n",
      "            for i in range(1,len(lims)):\n",
      "                if lims[i] > 0.5:\n",
      "                    step = 0.25\n",
      "                else:\n",
      "                    step = 0.05\n",
      "                in_bin_limits = np.arange(lims[i-1],lims[i],step)\n",
      "                all_bv,lims2 = np.histogram(input_vector,lims,weights=input_vector) #volume (l)  per bin (l/min range)\n",
      "            #WIP\n",
      "            #water_usage_lengths= length_WUsage(series,hp, Lim_Low = 0.1,LimHigh = 1000, averaged = False):\n",
      "            #figure()\n",
      "            #plot(water_usage_lengths,color) #color based on label of bin. => combine in piechart graph.\n",
      "#example\n",
      "lim =np.array([0,0.1,2,4,8,12,1000])\n",
      "Pie_WUsage(df,hp, lim,True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}